{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XseaUbhXGK6d"
      },
      "outputs": [],
      "source": [
        "# BaitDetector: Phishing URL Detection\n",
        "\n",
        "# Setup and Imports\n",
        "!pip install requests tldextract scikit-learn patool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eE5cbL8GGZE1"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from urllib.parse import urlparse\n",
        "import tldextract\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from io import StringIO\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_selection import RFE\n",
        "import re\n",
        "import seaborn as sns\n",
        "import random\n",
        "import time\n",
        "from sklearn.utils import resample\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import patoolib\n",
        "import tarfile\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"# 0. Preparing the dataset\n",
        "url = 'https://raw.githubusercontent.com/mitchellkrogza/Phishing.Database/master/ALL-phishing-links.tar.gz'\n",
        "response = requests.get(url, stream=True)\n",
        "file = 'temp.tar.gz'\n",
        "\n",
        "with open(file, 'wb') as f:\n",
        "    for chunk in response.iter_content(chunk_size=1024):\n",
        "        if chunk:\n",
        "            f.write(chunk)\n",
        "\n",
        "patoolib.extract_archive(file)\n",
        "\n",
        "with open('YOUR_FILE.txt', 'r') as f:\n",
        "    text = f.read()\"\"\""
      ],
      "metadata": {
        "id": "YYie6goGmOpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAfgss_XH84S"
      },
      "outputs": [],
      "source": [
        "# 1. Data Collection\n",
        "\n",
        "def fetch_phishing_urls_github(limit=50000):\n",
        "    \"\"\"Fetch phishing URLs from Mitchell Krogza's Phishing.Database on GitHub.\"\"\"\n",
        "    github_url = \"https://raw.githubusercontent.com/mitchellkrogza/Phishing.Database/master/ALL-phishing-links.tar.gz\"\n",
        "    try:\n",
        "        response = requests.get(github_url)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        # Create a BytesIO object from the response content\n",
        "        tar_bytes = io.BytesIO(response.content)\n",
        "\n",
        "        # Open the tar.gz file\n",
        "        with tarfile.open(fileobj=tar_bytes, mode='r:gz') as tar:\n",
        "            urls = []\n",
        "            # Iterate through all files in the archive\n",
        "            for member in tar.getmembers():\n",
        "                if member.name.endswith('.lst'):\n",
        "                    # Extract the .lst file content\n",
        "                    f = tar.extractfile(member)\n",
        "                    if f:\n",
        "                        content = f.read().decode('utf-8')\n",
        "                        urls.extend(content.strip().split('\\n'))\n",
        "\n",
        "        print(f\"Fetched {len(urls)} URLs from GitHub\")\n",
        "        return urls[:limit]\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching data from GitHub Phishing.Database: {e}\")\n",
        "        return []\n",
        "    except tarfile.TarError as e:\n",
        "        print(f\"Error processing tar.gz file: {e}\")\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        print(f\"Unexpected error: {e}\")\n",
        "        return []\n",
        "\n",
        "def fetch_legitimate_urls_majestic(limit=50000):\n",
        "    \"\"\"Fetch legitimate URLs from Majestic Million.\"\"\"\n",
        "    majestic_url = \"https://downloads.majestic.com/majestic_million.csv\"\n",
        "    try:\n",
        "        response = requests.get(majestic_url)\n",
        "        response.raise_for_status()\n",
        "        csv_content = StringIO(response.text)\n",
        "        df = pd.read_csv(csv_content, usecols=['Domain'], nrows=limit)\n",
        "        return [\"http://\" + domain for domain in df['Domain']]\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching data from Majestic Million: {e}\")\n",
        "        return []\n",
        "    except pd.errors.EmptyDataError:\n",
        "        print(\"The CSV file from Majestic Million is empty.\")\n",
        "        return []\n",
        "\n",
        "# Collect data\n",
        "print(\"Fetching phishing URLs from GitHub...\")\n",
        "phishing_urls = fetch_phishing_urls_github(50000)\n",
        "print(f\"Fetched a total of {len(phishing_urls)} phishing URLs\")\n",
        "\n",
        "print(\"\\nFetching legitimate URLs...\")\n",
        "legitimate_urls = fetch_legitimate_urls_majestic(50000)\n",
        "print(f\"Fetched {len(legitimate_urls)} legitimate URLs\")\n",
        "\n",
        "# Remove duplicates and ensure all URLs start with http/https\n",
        "phishing_urls = list(set([url for url in phishing_urls if url.startswith('http')]))\n",
        "legitimate_urls = list(set(legitimate_urls))\n",
        "\n",
        "# Shuffle URLs\n",
        "random.shuffle(phishing_urls)\n",
        "random.shuffle(legitimate_urls)\n",
        "\n",
        "# Balance the dataset\n",
        "min_urls = min(len(phishing_urls), len(legitimate_urls))\n",
        "if min_urls > 0:\n",
        "    phishing_urls = phishing_urls[:min_urls]\n",
        "    legitimate_urls = legitimate_urls[:min_urls]\n",
        "\n",
        "    print(f\"\\nFinal dataset:\")\n",
        "    print(f\"Collected {len(phishing_urls)} phishing URLs\")\n",
        "    print(f\"Collected {len(legitimate_urls)} legitimate URLs\")\n",
        "\n",
        "    # Display some examples\n",
        "    print(\"\\nExample phishing URLs:\")\n",
        "    print(phishing_urls[:5])\n",
        "    print(\"\\nExample legitimate URLs:\")\n",
        "    print(legitimate_urls[:5])\n",
        "\n",
        "    # Combine all URLs and create labels\n",
        "    all_urls = phishing_urls + legitimate_urls\n",
        "    labels = [1] * len(phishing_urls) + [0] * len(legitimate_urls)\n",
        "\n",
        "    # Shuffle the combined dataset\n",
        "    combined = list(zip(all_urls, labels))\n",
        "    random.shuffle(combined)\n",
        "    all_urls, labels = zip(*combined)\n",
        "\n",
        "    print(\"\\nDataset is ready for feature extraction and model training.\")\n",
        "else:\n",
        "    print(\"Error: Unable to collect enough URLs. Please check your internet connection and the source URLs.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcxGJu4yJwg9"
      },
      "outputs": [],
      "source": [
        "def extract_features(url):\n",
        "    parsed = urlparse(url)\n",
        "    extracted = tldextract.extract(url)\n",
        "\n",
        "    features = {\n",
        "        'length': len(url),\n",
        "        'num_dots': url.count('.'),\n",
        "        'num_hyphens': url.count('-'),\n",
        "        'num_underscores': url.count('_'),\n",
        "        'num_digits': sum(c.isdigit() for c in url),\n",
        "        'has_https': int(parsed.scheme == 'https'),\n",
        "        'domain_length': len(extracted.domain),\n",
        "        'num_subdomains': len(extracted.subdomain.split('.')) if extracted.subdomain else 0,\n",
        "        'has_ip': int(bool(re.match(r'\\d+\\.\\d+\\.\\d+\\.\\d+', extracted.domain))),\n",
        "        'has_at_symbol': int('@' in url),\n",
        "        'has_double_slash': int('//' in parsed.path),\n",
        "        'has_hex': int(any(c.isdigit() or c.lower() in 'abcdef' for c in url)),\n",
        "        'num_params': len(parsed.query.split('&')) if parsed.query else 0,\n",
        "        # Additional Lexical Features\n",
        "        'has_login': int('login' in url.lower()),\n",
        "        'has_verify': int('verify' in url.lower()),\n",
        "        'has_secure': int('secure' in url.lower()),\n",
        "    }\n",
        "\n",
        "    # Non-predefined features (TF-IDF)\n",
        "    tfidf = TfidfVectorizer(analyzer='char', ngram_range=(3,5), max_features=50)\n",
        "    url_features = tfidf.fit_transform([url])  # Fit on individual URL\n",
        "    feature_names = ['tfidf_' + f for f in tfidf.get_feature_names_out()]\n",
        "    features.update(dict(zip(feature_names, url_features.toarray()[0])))\n",
        "\n",
        "    return features\n",
        "\n",
        "# Extract features\n",
        "all_features = [extract_features(url) for url in all_urls]\n",
        "df = pd.DataFrame(all_features)\n",
        "df['label'] = labels\n",
        "\n",
        "tfidf = TfidfVectorizer(analyzer='char', ngram_range=(3,5), max_features=50)\n",
        "url_features = tfidf.fit_transform(all_urls)\n",
        "feature_names = ['tfidf_' + f for f in tfidf.get_feature_names_out()]\n",
        "url_feature_df = pd.DataFrame(url_features.toarray(), columns=feature_names)\n",
        "\n",
        "# Combine all features\n",
        "df_combined = pd.concat([df, url_feature_df], axis=1)\n",
        "\n",
        "\n",
        "# Prepare data for modeling\n",
        "X = df_combined.drop('label', axis=1)\n",
        "y = df_combined['label']\n",
        "\n",
        "# Feature selection\n",
        "rfe = RFE(estimator=RandomForestClassifier(n_estimators=100, random_state=42), n_features_to_select=20)\n",
        "X_selected = rfe.fit_transform(X, y)\n",
        "\n",
        "# Perform stratified k-fold cross-validation\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_scores = []\n",
        "\n",
        "for train_index, test_index in skf.split(X_selected, y):\n",
        "    X_train, X_test = X_selected[train_index], X_selected[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "    cv_scores.append(accuracy_score(y_test, y_pred))\n",
        "\n",
        "print(f\"Cross-validation scores: {cv_scores}\")\n",
        "print(f\"Mean CV score: {np.mean(cv_scores):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lr6IxRQJ0B8"
      },
      "outputs": [],
      "source": [
        "# 3. Model Training and Evaluation\n",
        "\n",
        "# Prepare data for modeling\n",
        "X = df_combined.drop('label', axis=1)\n",
        "y = df_combined['label']\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Train a Random Forest model\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Perform cross-validation\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_scores = cross_val_score(model, X, y, cv=cv, scoring='roc_auc')\n",
        "print(\"\\nCross-validation ROC AUC scores:\", cv_scores)\n",
        "print(\"Mean CV ROC AUC score:\", cv_scores.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3w_H1f6IE64"
      },
      "outputs": [],
      "source": [
        "# 4. Feature Importance\n",
        "\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': X.columns,\n",
        "    'importance': model.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"\\nTop 10 Most Important Features:\")\n",
        "print(feature_importance.head(10))\n",
        "\n",
        "# Visualization\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(feature_importance['feature'][:10], feature_importance['importance'][:10])\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.title('Top 10 Most Important Features')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Update this list to match your actual features\n",
        "numerical_features = ['length', 'num_dots', 'num_hyphens', 'num_digits', 'domain_length', 'num_params']\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
        "fig.suptitle('Distribution of Features by URL Type (Updated)', fontsize=16)\n",
        "\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, feature in enumerate(numerical_features):\n",
        "    sns.histplot(data=df_combined, x=feature, hue='label', multiple=\"stack\", ax=axes[i])\n",
        "    axes[i].set_title(f'Distribution of {feature}')\n",
        "    axes[i].legend(['Legitimate', 'Phishing'])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Additional visualization for binary features\n",
        "binary_features = ['has_https', 'has_ip', 'has_at_symbol', 'has_double_slash', 'has_hex']\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
        "fig.suptitle('Distribution of Binary Features by URL Type', fontsize=16)\n",
        "\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, feature in enumerate(binary_features):\n",
        "    sns.countplot(data=df_combined, x=feature, hue='label', ax=axes[i])\n",
        "    axes[i].set_title(f'Distribution of {feature}')\n",
        "    axes[i].legend(['Legitimate', 'Phishing'])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Correlation heatmap\n",
        "plt.figure(figsize=(20, 16))\n",
        "correlation_matrix = df_combined.corr()\n",
        "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', linewidths=0.5)\n",
        "plt.title('Correlation Heatmap of Features')\n",
        "plt.show()\n",
        "\n",
        "# Print some statistics about the dataset\n",
        "print(\"Statistics for Legitimate URLs:\")\n",
        "print(df_combined[df_combined['label'] == 0].describe())\n",
        "print(\"\\nStatistics for Phishing URLs:\")\n",
        "print(df_combined[df_combined['label'] == 1].describe())\n",
        "\n",
        "# Check for any perfect separators\n",
        "for feature in df_combined.columns:\n",
        "    if feature != 'label':\n",
        "        legitimate_max = df_combined[df_combined['label'] == 0][feature].max()\n",
        "        phishing_min = df_combined[df_combined['label'] == 1][feature].min()\n",
        "        if legitimate_max < phishing_min or phishing_min > legitimate_max:\n",
        "            print(f\"Perfect separator found: {feature}\")\n",
        "            print(f\"Legitimate max: {legitimate_max}\")\n",
        "            print(f\"Phishing min: {phishing_min}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59QrhTU2GJrO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Assuming you have your predictions in y_pred and true labels in y_test\n",
        "# If not, you'll need to run your model predictions first\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Create a confusion matrix display\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Legitimate', 'Phishing'])\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "disp.plot(cmap='Blues', values_format='d')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Print out the confusion matrix values\n",
        "print(\"Confusion Matrix:\")\n",
        "print(f\"True Negatives: {cm[0][0]}\")\n",
        "print(f\"False Positives: {cm[0][1]}\")\n",
        "print(f\"False Negatives: {cm[1][0]}\")\n",
        "print(f\"True Positives: {cm[1][1]}\")\n",
        "\n",
        "# Calculate and print additional metrics\n",
        "total = sum(sum(cm))\n",
        "accuracy = (cm[0][0] + cm[1][1]) / total\n",
        "precision = cm[1][1] / (cm[1][1] + cm[0][1])\n",
        "recall = cm[1][1] / (cm[1][1] + cm[1][0])\n",
        "f1_score = 2 * precision * recall / (precision + recall)\n",
        "\n",
        "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1_score:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
